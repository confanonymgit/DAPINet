{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dapinet.analysis import (\n",
    "    load_datasets,\n",
    "    run_model_inference,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variants to evaluate\n",
    "VARIANTS = [\n",
    "    \"DAPINet\",  # Base model\n",
    "    \"ablation_dace_simple\",\n",
    "    \"ablation_pool_mean\",\n",
    "    \"ablation_no_col_attn\",\n",
    "]\n",
    "\n",
    "VARIANT_LABELS = {\n",
    "    \"DAPINet\": \"Base (Full)\",\n",
    "    \"ablation_dace_simple\": \"DACE→Simple Stats\",\n",
    "    \"ablation_pool_mean\": \"PMA→Mean Pool\",\n",
    "    \"ablation_no_col_attn\": \"No Col. Attn.\",\n",
    "}\n",
    "\n",
    "# Paths\n",
    "MODELS_DIR = Path(\"models\")\n",
    "RESULTS_DIR = Path(\"results/ablation\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Data paths\n",
    "REAL_WORLD_DIR = Path(\"datasets/real_world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 09:44:40,333 INFO: Loading datasets from datasets\\real_world\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading real-world datasets from: datasets\\real_world\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Datasets: 100%|██████████| 20/20 [00:00<00:00, 593.82it/s]\n",
      "2026-01-28 09:44:40,375 INFO: Loaded 20 datasets.\n"
     ]
    }
   ],
   "source": [
    "# Load real-world datasets\n",
    "print(f\"Loading real-world datasets from: {REAL_WORLD_DIR}\")\n",
    "real_datasets = load_datasets(REAL_WORLD_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 09:44:43,978 INFO: Found 5 models in models\\DAPINet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Evaluating on Real-World: Base (Full)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 09:44:44,204 INFO: Updating Config from checkpoint_fold_1.pth...\n",
      "2026-01-28 09:44:44,231 INFO: Loaded model from models\\DAPINet\\checkpoint_fold_1.pth (Epoch 4, Loss 0.0456)\n",
      "2026-01-28 09:44:44,336 INFO: Updating Config from checkpoint_fold_2.pth...\n",
      "2026-01-28 09:44:44,357 INFO: Loaded model from models\\DAPINet\\checkpoint_fold_2.pth (Epoch 8, Loss 0.0461)\n",
      "2026-01-28 09:44:44,442 INFO: Updating Config from checkpoint_fold_3.pth...\n",
      "2026-01-28 09:44:44,460 INFO: Loaded model from models\\DAPINet\\checkpoint_fold_3.pth (Epoch 9, Loss 0.0513)\n",
      "2026-01-28 09:44:44,553 INFO: Updating Config from checkpoint_fold_4.pth...\n",
      "2026-01-28 09:44:44,572 INFO: Loaded model from models\\DAPINet\\checkpoint_fold_4.pth (Epoch 7, Loss 0.0482)\n",
      "2026-01-28 09:44:44,630 INFO: Updating Config from checkpoint_fold_5.pth...\n",
      "2026-01-28 09:44:44,644 INFO: Loaded model from models\\DAPINet\\checkpoint_fold_5.pth (Epoch 8, Loss 0.0447)\n",
      "Model Inference: 100%|██████████| 20/20 [00:02<00:00,  9.63it/s]\n",
      "2026-01-28 09:44:46,738 INFO: Found 5 models in models\\ablation_dace_simple\n",
      "2026-01-28 09:44:46,799 INFO: Updating Config from checkpoint_fold_1.pth...\n",
      "2026-01-28 09:44:46,816 INFO: Loaded model from models\\ablation_dace_simple\\checkpoint_fold_1.pth (Epoch 9, Loss 0.0573)\n",
      "2026-01-28 09:44:46,874 INFO: Updating Config from checkpoint_fold_2.pth...\n",
      "2026-01-28 09:44:46,890 INFO: Loaded model from models\\ablation_dace_simple\\checkpoint_fold_2.pth (Epoch 9, Loss 0.0516)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved to: results\\ablation\\real_world_DAPINet.csv\n",
      "\n",
      "============================================================\n",
      "Evaluating on Real-World: DACE→Simple Stats\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 09:44:46,952 INFO: Updating Config from checkpoint_fold_3.pth...\n",
      "2026-01-28 09:44:46,969 INFO: Loaded model from models\\ablation_dace_simple\\checkpoint_fold_3.pth (Epoch 8, Loss 0.0572)\n",
      "2026-01-28 09:44:47,035 INFO: Updating Config from checkpoint_fold_4.pth...\n",
      "2026-01-28 09:44:47,052 INFO: Loaded model from models\\ablation_dace_simple\\checkpoint_fold_4.pth (Epoch 9, Loss 0.0584)\n",
      "2026-01-28 09:44:47,108 INFO: Updating Config from checkpoint_fold_5.pth...\n",
      "2026-01-28 09:44:47,125 INFO: Loaded model from models\\ablation_dace_simple\\checkpoint_fold_5.pth (Epoch 9, Loss 0.0572)\n",
      "Model Inference: 100%|██████████| 20/20 [00:01<00:00, 16.62it/s]\n",
      "2026-01-28 09:44:48,338 INFO: Found 5 models in models\\ablation_pool_mean\n",
      "2026-01-28 09:44:48,392 INFO: Updating Config from checkpoint_fold_1.pth...\n",
      "2026-01-28 09:44:48,411 INFO: Loaded model from models\\ablation_pool_mean\\checkpoint_fold_1.pth (Epoch 9, Loss 0.0426)\n",
      "2026-01-28 09:44:48,477 INFO: Updating Config from checkpoint_fold_2.pth...\n",
      "2026-01-28 09:44:48,496 INFO: Loaded model from models\\ablation_pool_mean\\checkpoint_fold_2.pth (Epoch 7, Loss 0.0438)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved to: results\\ablation\\real_world_ablation_dace_simple.csv\n",
      "\n",
      "============================================================\n",
      "Evaluating on Real-World: PMA→Mean Pool\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 09:44:48,559 INFO: Updating Config from checkpoint_fold_3.pth...\n",
      "2026-01-28 09:44:48,585 INFO: Loaded model from models\\ablation_pool_mean\\checkpoint_fold_3.pth (Epoch 8, Loss 0.0463)\n",
      "2026-01-28 09:44:48,641 INFO: Updating Config from checkpoint_fold_4.pth...\n",
      "2026-01-28 09:44:48,663 INFO: Loaded model from models\\ablation_pool_mean\\checkpoint_fold_4.pth (Epoch 7, Loss 0.0506)\n",
      "2026-01-28 09:44:48,716 INFO: Updating Config from checkpoint_fold_5.pth...\n",
      "2026-01-28 09:44:48,733 INFO: Loaded model from models\\ablation_pool_mean\\checkpoint_fold_5.pth (Epoch 9, Loss 0.0448)\n",
      "Model Inference: 100%|██████████| 20/20 [00:01<00:00, 19.17it/s]\n",
      "2026-01-28 09:44:49,787 INFO: Found 5 models in models\\ablation_no_col_attn\n",
      "2026-01-28 09:44:49,835 INFO: Updating Config from checkpoint_fold_1.pth...\n",
      "2026-01-28 09:44:49,849 INFO: Loaded model from models\\ablation_no_col_attn\\checkpoint_fold_1.pth (Epoch 9, Loss 0.0603)\n",
      "2026-01-28 09:44:49,903 INFO: Updating Config from checkpoint_fold_2.pth...\n",
      "2026-01-28 09:44:49,917 INFO: Loaded model from models\\ablation_no_col_attn\\checkpoint_fold_2.pth (Epoch 7, Loss 0.0618)\n",
      "2026-01-28 09:44:49,975 INFO: Updating Config from checkpoint_fold_3.pth...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved to: results\\ablation\\real_world_ablation_pool_mean.csv\n",
      "\n",
      "============================================================\n",
      "Evaluating on Real-World: No Col. Attn.\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 09:44:50,004 INFO: Loaded model from models\\ablation_no_col_attn\\checkpoint_fold_3.pth (Epoch 7, Loss 0.0579)\n",
      "2026-01-28 09:44:50,084 INFO: Updating Config from checkpoint_fold_4.pth...\n",
      "2026-01-28 09:44:50,108 INFO: Loaded model from models\\ablation_no_col_attn\\checkpoint_fold_4.pth (Epoch 6, Loss 0.0603)\n",
      "2026-01-28 09:44:50,165 INFO: Updating Config from checkpoint_fold_5.pth...\n",
      "2026-01-28 09:44:50,178 INFO: Loaded model from models\\ablation_no_col_attn\\checkpoint_fold_5.pth (Epoch 6, Loss 0.0574)\n",
      "Model Inference: 100%|██████████| 20/20 [00:00<00:00, 26.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved to: results\\ablation\\real_world_ablation_no_col_attn.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run inference for each variant\n",
    "real_results = {}\n",
    "\n",
    "for variant in VARIANTS:\n",
    "    model_path = MODELS_DIR / variant\n",
    "\n",
    "    if not model_path.exists():\n",
    "        print(f\"⚠️  Skipping {variant} (model not found)\\n\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"Evaluating on Real-World: {VARIANT_LABELS[variant]}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    df_pred, stats = run_model_inference(model_path, real_datasets)\n",
    "\n",
    "    # Save results\n",
    "    output_file = RESULTS_DIR / f\"real_world_{variant}.csv\"\n",
    "    df_pred.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"  Saved to: {output_file}\")\n",
    "\n",
    "    real_results[variant] = df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1c65f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "REAL-WORLD ARI SUMMARY (by predicted top algo)\n",
      "============================================================\n",
      "          Variant  Mean Pred ARI  Median Pred ARI  Mean Regret  Median Regret  Within 10% of Max %\n",
      "      Base (Full)       0.352790         0.245972     0.048809       0.005170                 90.0\n",
      "DACE→Simple Stats       0.280008         0.187040     0.121591       0.057294                 65.0\n",
      "    PMA→Mean Pool       0.302165         0.189768     0.099433       0.017015                 75.0\n",
      "    No Col. Attn.       0.316549         0.245972     0.085049       0.017015                 70.0\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Real-world ARI analysis (per-variant)\n",
    "oracle_path = \"results/oracle_ari.csv\"\n",
    "oracle_df = pd.read_csv(oracle_path).set_index(\"dataset\")\n",
    "\n",
    "realworld_variant_stats = []\n",
    "\n",
    "for variant, df_pred in real_results.items():\n",
    "    if df_pred is None or df_pred.empty:\n",
    "        print(f\"⚠️  Skipping {VARIANT_LABELS[variant]} (no predictions)\")\n",
    "        continue\n",
    "\n",
    "    algo_cols = [\n",
    "        c\n",
    "        for c in df_pred.columns\n",
    "        if c not in {\"dataset\", \"inference_time_ms\"}\n",
    "    ]\n",
    "    per_dataset = []\n",
    "\n",
    "    for _, row in df_pred.iterrows():\n",
    "        ds_name = row[\"dataset\"]\n",
    "        if ds_name not in oracle_df.index:\n",
    "            continue\n",
    "\n",
    "        probs = row[algo_cols].to_numpy(dtype=float)\n",
    "        pred_idx = int(np.argmax(probs))\n",
    "        pred_algo = algo_cols[pred_idx]\n",
    "        valid_cols = [c for c in algo_cols if c in oracle_df.columns]\n",
    "        if not valid_cols:\n",
    "            continue\n",
    "\n",
    "        true_ari_row = oracle_df.loc[ds_name, valid_cols]\n",
    "        pred_ari = float(true_ari_row[pred_algo])\n",
    "        max_true_ari = float(true_ari_row.max())\n",
    "        regret = max_true_ari - pred_ari\n",
    "\n",
    "        per_dataset.append(\n",
    "            {\n",
    "                \"dataset\": ds_name,\n",
    "                \"pred_algo\": pred_algo,\n",
    "                \"pred_ari\": pred_ari,\n",
    "                \"max_true_ari\": max_true_ari,\n",
    "                \"regret\": regret,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if not per_dataset:\n",
    "        print(f\"⚠️  Skipping {VARIANT_LABELS[variant]} (no matching oracle ARIs)\")\n",
    "        continue\n",
    "\n",
    "    ds_df = pd.DataFrame(per_dataset)\n",
    "\n",
    "    realworld_variant_stats.append(\n",
    "        {\n",
    "            \"Variant\": VARIANT_LABELS[variant],\n",
    "            \"Mean Pred ARI\": ds_df[\"pred_ari\"].mean(),\n",
    "            \"Median Pred ARI\": ds_df[\"pred_ari\"].median(),\n",
    "            \"Mean Regret\": ds_df[\"regret\"].mean(),\n",
    "            \"Median Regret\": ds_df[\"regret\"].median(),\n",
    "            \"Within 10% of Max %\": (ds_df[\"regret\"] <= 0.1).mean() * 100,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Save per-dataset stats for inspection\n",
    "    ds_df.to_csv(RESULTS_DIR / f\"real_world_ari_{variant}.csv\", index=False)\n",
    "\n",
    "realworld_summary_df = pd.DataFrame(realworld_variant_stats)\n",
    "realworld_summary_df.to_csv(RESULTS_DIR / \"real_world_ari_summary.csv\", index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"REAL-WORLD ARI SUMMARY (by predicted top algo)\")\n",
    "print(\"=\" * 60)\n",
    "print(realworld_summary_df.to_string(index=False))\n",
    "print(\"=\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
