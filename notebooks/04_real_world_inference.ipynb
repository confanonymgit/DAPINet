{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdf6269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from dapinet.analysis.real_world_data import load_datasets, run_model_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1aeb62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 10:38:13,925 INFO: Loading datasets from datasets\\real_world\n",
      "Loading Datasets: 100%|██████████| 20/20 [00:00<00:00, 923.19it/s]\n",
      "2026-01-28 10:38:13,951 INFO: Loaded 20 datasets.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 datasets.\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(\"datasets/real_world\")\n",
    "model_path = Path(\"models/DAPINet\")\n",
    "\n",
    "datasets = load_datasets(data_path)\n",
    "if not datasets:\n",
    "    print(\"No datasets loaded. Exiting.\")\n",
    "\n",
    "print(f\"Loaded {len(datasets)} datasets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec57ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 10:38:15,810 INFO: Found 5 models in models\\DAPINet\n",
      "2026-01-28 10:38:15,930 INFO: Updating Config from checkpoint_fold_1.pth...\n",
      "2026-01-28 10:38:15,946 INFO: Loaded model from models\\DAPINet\\checkpoint_fold_1.pth (Epoch 4, Loss 0.0456)\n",
      "2026-01-28 10:38:15,983 INFO: Updating Config from checkpoint_fold_2.pth...\n",
      "2026-01-28 10:38:15,998 INFO: Loaded model from models\\DAPINet\\checkpoint_fold_2.pth (Epoch 8, Loss 0.0461)\n",
      "2026-01-28 10:38:16,038 INFO: Updating Config from checkpoint_fold_3.pth...\n",
      "2026-01-28 10:38:16,052 INFO: Loaded model from models\\DAPINet\\checkpoint_fold_3.pth (Epoch 9, Loss 0.0513)\n",
      "2026-01-28 10:38:16,095 INFO: Updating Config from checkpoint_fold_4.pth...\n",
      "2026-01-28 10:38:16,109 INFO: Loaded model from models\\DAPINet\\checkpoint_fold_4.pth (Epoch 7, Loss 0.0482)\n",
      "2026-01-28 10:38:16,158 INFO: Updating Config from checkpoint_fold_5.pth...\n",
      "2026-01-28 10:38:16,178 INFO: Loaded model from models\\DAPINet\\checkpoint_fold_5.pth (Epoch 8, Loss 0.0447)\n",
      "Model Inference: 100%|██████████| 20/20 [00:01<00:00, 13.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved per-dataset inference time to: results\\DAPINet_inference_time.csv\n",
      "Saved detailed inference results to: results\\DAPINet_results.csv\n"
     ]
    }
   ],
   "source": [
    "df_pred, stats = run_model_inference(model_path, datasets)\n",
    "\n",
    "# Save comprehensive results\n",
    "output_path = Path(\"results\")\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "output_file = output_path / \"DAPINet_results.csv\"\n",
    "df_pred.to_csv(output_file, index=False)\n",
    "\n",
    "# Save per-dataset inference time\n",
    "if \"inference_time_ms\" in df_pred.columns:\n",
    "    time_output = output_path / \"DAPINet_inference_time.csv\"\n",
    "    df_pred[[\"dataset\", \"inference_time_ms\"]].to_csv(time_output, index=False)\n",
    "    print(f\"Saved per-dataset inference time to: {time_output}\")\n",
    "\n",
    "print(f\"Saved detailed inference results to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8c5d7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 10:38:27,128 INFO: Found 5 models in models\\DAPINet\n",
      "2026-01-28 10:38:27,202 INFO: Updating Config from checkpoint_fold_1.pth...\n",
      "2026-01-28 10:38:27,221 INFO: Loaded model from models\\DAPINet\\checkpoint_fold_1.pth (Epoch 4, Loss 0.0456)\n",
      "2026-01-28 10:38:27,265 INFO: Updating Config from checkpoint_fold_2.pth...\n",
      "2026-01-28 10:38:27,279 INFO: Loaded model from models\\DAPINet\\checkpoint_fold_2.pth (Epoch 8, Loss 0.0461)\n",
      "2026-01-28 10:38:27,330 INFO: Updating Config from checkpoint_fold_3.pth...\n",
      "2026-01-28 10:38:27,345 INFO: Loaded model from models\\DAPINet\\checkpoint_fold_3.pth (Epoch 9, Loss 0.0513)\n",
      "2026-01-28 10:38:27,391 INFO: Updating Config from checkpoint_fold_4.pth...\n",
      "2026-01-28 10:38:27,408 INFO: Loaded model from models\\DAPINet\\checkpoint_fold_4.pth (Epoch 7, Loss 0.0482)\n",
      "2026-01-28 10:38:27,447 INFO: Updating Config from checkpoint_fold_5.pth...\n",
      "2026-01-28 10:38:27,460 INFO: Loaded model from models\\DAPINet\\checkpoint_fold_5.pth (Epoch 8, Loss 0.0447)\n",
      "Model Inference: 100%|██████████| 20/20 [00:00<00:00, 24.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Permutation test:\n",
      "  Max abs diff per dataset (predictions): {'count': 20.0, 'mean': 6.705522537231445e-08, 'std': 2.3929925815670675e-08, 'min': 2.9802322387695312e-08, '25%': 5.960464477539063e-08, '50%': 5.960464477539063e-08, '75%': 5.960464477539063e-08, 'max': 1.1920928955078125e-07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test permutation invariance by shuffling feature columns and re-running inference\n",
    "rng = np.random.default_rng(seed=42)\n",
    "permuted_datasets: dict[str, dict] = {}\n",
    "for name, ds in datasets.items():\n",
    "    X = ds[\"X\"]\n",
    "    perm = rng.permutation(X.shape[1])\n",
    "    permuted_entry = {\"X\": X[:, perm].copy()}\n",
    "    for optional_key in (\"y\", \"ari\"):\n",
    "        if optional_key in ds:\n",
    "            permuted_entry[optional_key] = ds[optional_key]\n",
    "    permuted_datasets[name] = permuted_entry\n",
    "\n",
    "# Run inference on permuted columns\n",
    "permuted_pred, perm_stats = run_model_inference(model_path, permuted_datasets)\n",
    "\n",
    "algo_cols = [\n",
    "    c\n",
    "    for c in df_pred.columns\n",
    "    if c not in (\"dataset\", \"inference_time_ms\", \"n_rows\", \"n_cols\")\n",
    "    and c in permuted_pred.columns\n",
    "    and np.issubdtype(df_pred[c].dtype, np.number)\n",
    " ]\n",
    "diff = df_pred.set_index(\"dataset\")[algo_cols].subtract(\n",
    "    permuted_pred.set_index(\"dataset\")[algo_cols], fill_value=np.nan\n",
    ")\n",
    "max_abs_diff = diff.abs().max(axis=1)\n",
    "\n",
    "print(\"\\nPermutation test:\")\n",
    "print(f\"  Max abs diff per dataset (predictions): {max_abs_diff.describe().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08544d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved selected algorithms to: results\\DAPINet_results.csv\n"
     ]
    }
   ],
   "source": [
    "# create dataframe with selected algorithm and its value per dataset\n",
    "# include per-dataset inference time for convenience\n",
    "df_out = df_pred[[\"dataset\"]].copy()\n",
    "if \"inference_time_ms\" in df_pred.columns:\n",
    "    df_out[\"inference_time_ms\"] = df_pred[\"inference_time_ms\"]\n",
    "\n",
    "algo_cols = df_pred.drop(\n",
    "    columns=[col for col in [\"dataset\", \"inference_time_ms\"] if col in df_pred.columns]\n",
    ")\n",
    "df_out[\"selected_algorithm\"] = algo_cols.idxmax(axis=1)\n",
    "df_out[\"value\"] = algo_cols.max(axis=1)\n",
    "\n",
    "# save results\n",
    "output_file_selected = output_path / \"DAPINet_results.csv\"\n",
    "df_out.to_csv(output_file_selected, index=False)\n",
    "\n",
    "print(f\"Saved selected algorithms to: {output_file_selected}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
